{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d480d0b",
   "metadata": {},
   "source": [
    "# Trigonometry (1) | Exploring the unit cirlce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a915b8f",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d594bd62",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c2bcec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd7fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Sampling behaviour & structure — Random vs Sobol (2D)\n",
    "# -----------------------------------------------------------------------------\n",
    "# Function:\n",
    "#   - Show how sampling \"fills space\" differently (coverage, gaps, clustering)\n",
    "#\n",
    "# What you get:\n",
    "#   (A) Scatter: Random vs Sobol (side-by-side)\n",
    "#   (B) 2D bin-count heatmaps: where samples concentrate\n",
    "#   (C) Nearest-neighbour distance histogram: clustering signature\n",
    "#   (D) Simple metrics: discrepancy proxy + min NN distance stats\n",
    "#\n",
    "# Notes:\n",
    "#   - Sobol uses SciPy's QMC (scipy>=1.7). If not installed, fallback to Halton.\n",
    "#   - Designed to match repo style: compact header, explain-in-plot callout,\n",
    "#     widget controls in a single row.\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import qmc\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"font.family\": \"serif\",\n",
    "    \"mathtext.fontset\": \"cm\",\n",
    "    \"axes.unicode_minus\": False,\n",
    "})\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b468a8e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fcbcf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60ee11a914949fa8e5763265afcc6b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=8, continuous_update=False, description='m', max=12, min=4), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Beautiful \"LaTeX-style\" sampling comparison in Jupyter\n",
    "#   1) np.random (uniform)\n",
    "#   2) Sobol (unscrambled)\n",
    "#   3) Sobol (scrambled)  <-- slider controls its seed\n",
    "#   4) Nearest-neighbour distance distribution\n",
    "# =============================================================================\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "m_power = 8\n",
    "N = 2 ** m_power\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers\n",
    "# -----------------------------\n",
    "def style_square(ax, title):\n",
    "    ax.set_title(title, fontsize=16, pad=10)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_xticks([0, 0.5, 1.0])\n",
    "    ax.set_yticks([0, 0.5, 1.0])\n",
    "    ax.grid(True, alpha=0.20)\n",
    "    ax.plot([0, 1, 1, 0, 0], [0, 0, 1, 1, 0], lw=2)\n",
    "    ax.tick_params(labelsize=11)\n",
    "\n",
    "def hist_with_kde(ax, data, bins, label=None):\n",
    "    # Histogram (normalized)\n",
    "    ax.hist(data, bins=bins, density=True, alpha=0.6)\n",
    "\n",
    "    # KDE (smooth density)\n",
    "    kde = gaussian_kde(data)\n",
    "    x = np.linspace(data.min(), data.max(), 400)\n",
    "    ax.plot(x, kde(x), linewidth=2)\n",
    "\n",
    "    if label is not None:\n",
    "        ax.set_title(label, fontsize=14)\n",
    "\n",
    "def nearest_neighbor_distances(X):\n",
    "    # O(N^2) but fine for N=1024\n",
    "    diff = X[:, None, :] - X[None, :, :]\n",
    "    D2 = np.sum(diff**2, axis=-1)\n",
    "    np.fill_diagonal(D2, np.inf)\n",
    "    return np.sqrt(np.min(D2, axis=1))\n",
    "\n",
    "\n",
    "def style_nn(ax, title):\n",
    "    ax.set_title(title, fontsize=14, pad=8)\n",
    "    ax.set_xlabel(r\"$d_{\\mathrm{NN}}$\", fontsize=12)\n",
    "    ax.set_ylabel(\"Density\", fontsize=12)\n",
    "    ax.set_xlim(0.0, 0.12)\n",
    "    ax.set_ylim(0, 100)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "    ax.tick_params(labelsize=10)\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Main plotting function (called by the slider)\n",
    "# =============================================================================\n",
    "def plot_sampling(m_power=8, scramble_seed=1):\n",
    "    # ONLY change: m_power is now dynamic, and N is recomputed from it\n",
    "    m_power = int(m_power)\n",
    "    N = 2 ** m_power\n",
    "\n",
    "    # 1) np.random\n",
    "    rng = np.random.default_rng(int(scramble_seed))\n",
    "    X_rand = rng.random((N, 2))\n",
    "\n",
    "    # 2) Sobol (unscrambled)\n",
    "    sobol_plain = qmc.Sobol(d=2, scramble=False)\n",
    "    X_sobol = sobol_plain.random_base2(m=m_power)\n",
    "\n",
    "    # 3) Sobol (scrambled)\n",
    "    sobol_scr = qmc.Sobol(d=2, scramble=True, seed=int(scramble_seed))\n",
    "    X_scr = sobol_scr.random_base2(m=m_power)\n",
    "\n",
    "    # NN distances\n",
    "    d_rand = nearest_neighbor_distances(X_rand)\n",
    "    d_sob  = nearest_neighbor_distances(X_sobol)\n",
    "    d_scr  = nearest_neighbor_distances(X_scr)\n",
    "\n",
    "    # Common bins for comparability\n",
    "    d_all = np.concatenate([d_rand, d_sob, d_scr])\n",
    "    bins = np.linspace(d_all.min(), d_all.max(), 45)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Figure layout (4x2) as requested\n",
    "    #   Top row: 3 scatters + (optional) overlay NN\n",
    "    #   Bottom row: NN under each + (optional) notes/empty\n",
    "    # -----------------------------\n",
    "    fig = plt.figure(figsize=(22, 10.2))\n",
    "    gs = fig.add_gridspec(\n",
    "        nrows=2, ncols=4,\n",
    "        left=0.04, right=0.98,\n",
    "        bottom=0.10, top=0.86,\n",
    "        wspace=0.18, hspace=0.28\n",
    "    )\n",
    "\n",
    "    axA = fig.add_subplot(gs[0, 0])\n",
    "    axB = fig.add_subplot(gs[0, 1])\n",
    "    axC = fig.add_subplot(gs[0, 2])\n",
    "    axD = fig.add_subplot(gs[0, 3])  # overlay panel (optional)\n",
    "\n",
    "    axA_nn = fig.add_subplot(gs[1, 0])\n",
    "    axB_nn = fig.add_subplot(gs[1, 1])\n",
    "    axC_nn = fig.add_subplot(gs[1, 2])\n",
    "    axD_nn = fig.add_subplot(gs[1, 3])  # keep as notes/empty for now\n",
    "\n",
    "    fig.suptitle(\n",
    "        rf\"Uniform Sampling in $[0,1]^2$  (N = {N})  —  Scrambled seed = {int(scramble_seed)}\",\n",
    "        fontsize=20,\n",
    "        y=0.95\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Top row scatters\n",
    "    # -----------------------------\n",
    "    axA.scatter(X_rand[:, 0], X_rand[:, 1], s=14, alpha=0.85)\n",
    "    style_square(axA, r\"(A) $\\mathrm{np.random}$ (pseudo-random)\")\n",
    "\n",
    "    axB.scatter(X_sobol[:, 0], X_sobol[:, 1], s=14, alpha=0.85)\n",
    "    style_square(axB, r\"(B) Sobol (unscrambled)\")\n",
    "\n",
    "    axC.scatter(X_scr[:, 0], X_scr[:, 1], s=14, alpha=0.85)\n",
    "    style_square(axC, r\"(C) Sobol (scrambled)\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Top-right panel: overlay NN distributions (kept simple)\n",
    "    # -----------------------------\n",
    "    axD.hist(d_rand, bins=bins, density=True, alpha=0.60, label=\"Random\")\n",
    "    axD.hist(d_sob,  bins=bins, density=True, alpha=0.60, label=\"Sobol\")\n",
    "    axD.hist(d_scr,  bins=bins, density=True, alpha=0.60, label=\"Scrambled Sobol\")\n",
    "    axD.set_title(r\"(D) NN distance (overlay)\", fontsize=16, pad=10)\n",
    "    axD.set_xlabel(r\"$d_{\\mathrm{NN}}$\")\n",
    "    axD.set_ylabel(\"Density\")\n",
    "    axD.grid(True, alpha=0.25)\n",
    "    axD.legend(frameon=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Bottom row: NN under each representation\n",
    "    # -----------------------------\n",
    "    hist_with_kde(axA_nn, d_rand, bins, r\"NN distribution for (A)\")\n",
    "    axA_nn.axvline(np.mean(d_rand), linestyle=\"--\", linewidth=2, label=r\"$\\langle d_{\\mathrm{NN}} \\rangle$\")\n",
    "    style_nn(axA_nn, r\"NN distances for (A)\")\n",
    "\n",
    "    hist_with_kde(axB_nn, d_sob, bins, r\"NN distribution for (B)\")\n",
    "    axB_nn.axvline(np.mean(d_sob), linestyle=\"--\", linewidth=2)\n",
    "    style_nn(axB_nn, r\"NN distances for (B)\")\n",
    "\n",
    "    hist_with_kde(axC_nn, d_scr, bins, r\"NN distribution for (C)\")\n",
    "    axC_nn.axvline(np.mean(d_scr), linestyle=\"--\", linewidth=2)\n",
    "    style_nn(axC_nn, r\"NN distances for (C)\")\n",
    "\n",
    "    # Bottom-right: keep clean (notes panel)\n",
    "    axD_nn.axis(\"off\")\n",
    "    axD_nn.text(\n",
    "        0.02, 0.98,\n",
    "        \"Interpretation:\\n\"\n",
    "        r\"• Random → heavier left tail (very small $d_{\\mathrm{NN}}$ clusters)\"\n",
    "        \"\\n\"\n",
    "        r\"• Sobol → suppresses tiny $d_{\\mathrm{NN}}$ while staying space-filling\"\n",
    "        \"\\n\"\n",
    "        r\"• Scrambling keeps low-discrepancy but removes visible lattice structure\",\n",
    "        va=\"top\", ha=\"left\",\n",
    "        fontsize=12,\n",
    "        bbox=dict(boxstyle=\"round,pad=0.5\", alpha=0.10)\n",
    "    )\n",
    "\n",
    "    fig.text(\n",
    "        0.5, 0.03,\n",
    "        r\"Unscrambled Sobol is deterministic/structured; scrambling randomizes while preserving low-discrepancy.\",\n",
    "        ha=\"center\",\n",
    "        fontsize=12,\n",
    "        alpha=0.85\n",
    "    )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Sliders: ONLY added m slider (plus existing seed slider)\n",
    "# =============================================================================\n",
    "interact(\n",
    "    plot_sampling,\n",
    "    m_power=IntSlider(\n",
    "        value=m_power, min=4, max=12, step=1,\n",
    "        description=\"m\",\n",
    "        continuous_update=False\n",
    "    ),\n",
    "    scramble_seed=IntSlider(\n",
    "        value=1, min=0, max=999, step=1,\n",
    "        description=\"seed\",\n",
    "        continuous_update=True\n",
    "    )\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab0a784",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a30e7c",
   "metadata": {},
   "source": [
    "At first glance, we could say that **scrambled Sobol explores more of the space evenly**, while `np.random` concentrates much of its nearest-neighbour (NN) distribution around a characteristic mean (as seen in the NN plots). However, increasing **m** produces a similar left-shift in NN distances for *all* samplers.\n",
    "\n",
    "This naturally raises the question:\n",
    "\n",
    "### Does increasing **m** make nearest-neighbour distances worse?\n",
    "\n",
    "The short answer is **no** — although it can look that way if NN distances are interpreted incorrectly.\n",
    "\n",
    "Below is the correct way to read what is happening.\n",
    "\n",
    "### What increasing **m** actually does\n",
    "\n",
    "In this notebook, the number of sample points is defined as\n",
    "\n",
    "$$\n",
    "N = 2^m\n",
    "$$\n",
    "\n",
    "As **m** increases:\n",
    "\n",
    "- The number of points grows exponentially  \n",
    "- All points remain within the fixed domain $[0,1]^2$  \n",
    "- Points are therefore forced to pack closer together  \n",
    "\n",
    "From geometry alone, the characteristic nearest-neighbour distance in 2D scales as\n",
    "\n",
    "$$\n",
    "d_{\\mathrm{NN}} \\sim N^{-1/2} = 2^{-m/2}\n",
    "$$\n",
    "\n",
    "Therefore, **NN distances must decrease as m increases** — for *any* sampling method.\n",
    "\n",
    "This behaviour is unavoidable and expected.\n",
    "\n",
    "### Why this is *not* counter-productive\n",
    "\n",
    "A smaller NN distance at higher **m** does **not** indicate poorer sampling.\n",
    "\n",
    "It simply reflects:\n",
    "\n",
    "- Higher sampling resolution  \n",
    "- Finer filling of the same domain  \n",
    "\n",
    "This occurs for:\n",
    "\n",
    "- `np.random`  \n",
    "- Sobol (unscrambled)  \n",
    "- Sobol (scrambled)  \n",
    "- Any reasonable space-filling sampler  \n",
    "\n",
    "As a result, the *absolute* value of NN distance is **not** a standalone quality metric.\n",
    "\n",
    "### What NN distance is actually telling us\n",
    "\n",
    "Nearest-neighbour distance is a **structural diagnostic**, not an absolute score.\n",
    "\n",
    "It should be used to compare:\n",
    "\n",
    "- Different sampling methods **at the same value of m**  \n",
    "- The **shape** of the NN distribution, not its raw scale  \n",
    "\n",
    "At fixed **m**, the meaningful distinctions are:\n",
    "\n",
    "- **Random sampling**\n",
    "  - Heavy left tail  \n",
    "  - Very small NN distances (clustering)\n",
    "- **Sobol (unscrambled)**\n",
    "  - Suppressed left tail  \n",
    "  - More regular spacing\n",
    "- **Sobol (scrambled)**\n",
    "  - Similar spacing guarantees  \n",
    "  - Reduced visible lattice structure  \n",
    "\n",
    "These qualitative differences persist for all values of **m**.\n",
    "\n",
    "### What *would* be a mistake\n",
    "\n",
    "It would be incorrect to compare NN distances across different values of **m** and conclude:\n",
    "\n",
    "> “This sampler is worse because its NN distances are smaller.”\n",
    "\n",
    "Such a conclusion ignores the intrinsic density scaling built into the problem.\n",
    "\n",
    "### How increasing **m** should be interpreted\n",
    "\n",
    "Increasing **m** does not degrade NN distances — it increases **resolution**.\n",
    "\n",
    "The correct question is:\n",
    "\n",
    "> As resolution increases, does the sampling preserve its structural character?\n",
    "\n",
    "Good samplers:\n",
    "\n",
    "- Scale predictably as $N$ increases  \n",
    "- Maintain the shape of their NN distributions  \n",
    "- Suppress extreme clustering  \n",
    "\n",
    "Poor samplers:\n",
    "\n",
    "- Develop heavy left tails  \n",
    "- Exhibit unstable scaling behaviour  \n",
    "- Produce voids and clumps  \n",
    "\n",
    "From this perspective, increasing **m** is not counter-productive — it is **diagnostically useful**.\n",
    "\n",
    "### (Advanced) Making NN distances comparable across **m**\n",
    "\n",
    "To compare NN structure *across different values of m*, the trivial density scaling should be removed by normalisation:\n",
    "\n",
    "$$\n",
    "\\tilde d_{\\mathrm{NN}} = d_{\\mathrm{NN}} \\sqrt{N}\n",
    "$$\n",
    "\n",
    "This produces a scale-free NN distance:\n",
    "\n",
    "- Differences reflect structure rather than density  \n",
    "- Distributions become comparable across resolutions  \n",
    "\n",
    "This is the mathematically correct approach once you move beyond demonstrations.\n",
    "\n",
    "### Summary: how to read the plots\n",
    "\n",
    "- Smaller NN distances at higher **m** are expected  \n",
    "- NN distance is meaningful only when comparing samplers at the same **m**  \n",
    "- Increasing **m** improves resolution; it does not degrade sampling  \n",
    "- Structural differences live in the **distribution shape**, not the raw scale  \n",
    "\n",
    "If NN distances shrink *while structure is preserved*, the sampler is behaving correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed56bed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd221260a944afca61180f57aef9138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=8, continuous_update=False, description='m', max=12, min=4), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Scale-free nearest-neighbour distribution:  d̃_NN = d_NN * sqrt(N)\n",
    "# -----------------------------------------------------------------------------\n",
    "# ONE plot only:\n",
    "#   - Overlay KDE(+hist) of normalized NN distances for:\n",
    "#       (A) Random\n",
    "#       (B) Sobol (unscrambled)\n",
    "#       (C) Sobol (scrambled; controlled by seed)\n",
    "#\n",
    "# Sliders:\n",
    "#   - m_power  (N = 2^m_power)\n",
    "#   - seed     (controls RNG + scrambled Sobol seed)\n",
    "# =============================================================================\n",
    "\n",
    "def nearest_neighbor_distances(X):\n",
    "    diff = X[:, None, :] - X[None, :, :]\n",
    "    D2 = np.sum(diff**2, axis=-1)\n",
    "    np.fill_diagonal(D2, np.inf)\n",
    "    return np.sqrt(np.min(D2, axis=1))\n",
    "\n",
    "\n",
    "def plot_scale_free_nn(m_power=8, seed=1):\n",
    "    m_power = int(m_power)\n",
    "    seed = int(seed)\n",
    "    N = 2 ** m_power\n",
    "\n",
    "    # --- Samples\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X_rand = rng.random((N, 2))\n",
    "\n",
    "    sobol_plain = qmc.Sobol(d=2, scramble=False)\n",
    "    X_sobol = sobol_plain.random_base2(m=m_power)\n",
    "\n",
    "    sobol_scr = qmc.Sobol(d=2, scramble=True, seed=seed)\n",
    "    X_scr = sobol_scr.random_base2(m=m_power)\n",
    "\n",
    "    # --- NN distances\n",
    "    d_rand = nearest_neighbor_distances(X_rand) * np.sqrt(N)\n",
    "    d_sob  = nearest_neighbor_distances(X_sobol) * np.sqrt(N)\n",
    "    d_scr  = nearest_neighbor_distances(X_scr) * np.sqrt(N)\n",
    "\n",
    "    # --- Shared x grid for KDE\n",
    "    all_d = np.concatenate([d_rand, d_sob, d_scr])\n",
    "    x = np.linspace(all_d.min(), all_d.max(), 600)\n",
    "\n",
    "    # --- Plot (single axis)\n",
    "    fig, ax = plt.subplots(figsize=(10.8, 5.6))\n",
    "\n",
    "    # Histograms (density)\n",
    "    bins = np.linspace(all_d.min(), all_d.max(), 55)\n",
    "    ax.hist(d_rand, bins=bins, density=True, alpha=0.30, label=\"Random\")\n",
    "    ax.hist(d_sob,  bins=bins, density=True, alpha=0.30, label=\"Sobol\")\n",
    "    ax.hist(d_scr,  bins=bins, density=True, alpha=0.30, label=\"Scrambled Sobol\")\n",
    "\n",
    "    # KDE curves\n",
    "    ax.plot(x, gaussian_kde(d_rand)(x), linewidth=2.2)\n",
    "    ax.plot(x, gaussian_kde(d_sob)(x),  linewidth=2.2)\n",
    "    ax.plot(x, gaussian_kde(d_scr)(x),  linewidth=2.2)\n",
    "\n",
    "    ax.set_title(\n",
    "        rf\"Scale-free NN spacing in $[0,1]^2$: $\\tilde d_{{NN}} = d_{{NN}}\\sqrt{{N}}$  (N = {N}, seed = {seed})\",\n",
    "        fontsize=16,\n",
    "        pad=12\n",
    "    )\n",
    "    ax.set_xlabel(r\"$\\tilde d_{\\mathrm{NN}} = d_{\\mathrm{NN}}\\sqrt{N}$\", fontsize=13)\n",
    "    ax.set_ylabel(\"Density\", fontsize=13)\n",
    "    ax.grid(True, alpha=0.25)\n",
    "    ax.legend(frameon=True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "interact(\n",
    "    plot_scale_free_nn,\n",
    "    m_power=IntSlider(value=8, min=4, max=12, step=1, description=\"m\", continuous_update=False),\n",
    "    seed=IntSlider(value=1, min=0, max=999, step=1, description=\"seed\", continuous_update=True),\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d006b7f",
   "metadata": {},
   "source": [
    "## conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747cc7d5",
   "metadata": {},
   "source": [
    "In conclusion, **scrambled Sobol explores the space more evenly at a fixed resolution**, suppressing very small nearest-neighbour distances and reducing clustering compared to `np.random`, which exhibits a heavier left tail in its NN distribution. The apparent left-shift of NN distances observed when increasing **m** occurs for *all* samplers and reflects a universal geometric effect of higher point density rather than a degradation in sampling quality. Consequently, NN distance should be interpreted as a **relative structural diagnostic at fixed m**, not as an absolute measure across different resolutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ChemicalBiology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
